{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRO3600 - Curseur Oculaire.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_kGzfdBQpcsa",
        "4WvdOep4phgS"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKS22qpkpMUe"
      },
      "source": [
        "# Image Processing\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEtVu57Xp0xS"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Renvoie le vecteur déplacement de la pupille entre 2 images\n",
        "def getPupilVector(lastPos, currentPos):\n",
        "    return [lastPos[0] - currentPos[0], lastPos[1] - currentPos[1]]\n",
        "\n",
        "\n",
        "# Renvoie la position de la pupille par rapport à la glande lacrimale\n",
        "def getPupilPosition(image):\n",
        "    # Extraction de l'imagette de l'oeil supérieur droit détecté\n",
        "    eye_color = extractEyesPicture(image)\n",
        "    # Condition de détection\n",
        "    if eye_color is None:\n",
        "        return [0, 0]\n",
        "\n",
        "    # Passage en noir et blanc pour la réduction d'information et une meilleure détection\n",
        "    gray = cv2.cvtColor(eye_color, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Détection de cercle dans l'imagette de l'oeil par la méthode de Hough\n",
        "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1.2, 100)\n",
        "\n",
        "    # Condition de détection d'un cercle\n",
        "    if circles is None:\n",
        "        return [0, 0]\n",
        "\n",
        "    # Récupération de la taille de l'image\n",
        "    rows, cols = gray.shape\n",
        "    # Application d'un flou gaussien\n",
        "    gray_blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "    # Seuillage\n",
        "    _, threshold = cv2.threshold(gray_blurred, 80, 255, cv2.THRESH_BINARY_INV)\n",
        "    # Recherche des contours de l'oeil\n",
        "    contours = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Conditions de détection de l'oeil\n",
        "    if contours is None:\n",
        "        return [0, 0]\n",
        "    if len(contours) == 0:\n",
        "        return [0, 0]\n",
        "\n",
        "    # Récupération des coordonnées de la pupille\n",
        "    (x, y, w, h) = cv2.boundingRect(contours[0])\n",
        "\n",
        "    return [x + int(w / 2), y + int(h / 2)]\n",
        "\n",
        "\n",
        "# Extrait une imagette de l'oeil supérieur droit\n",
        "def extractEyesPicture(image):\n",
        "    # Méthode des ondelettes de Haar pour la détection des yeux\n",
        "    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "    # Définiton de l'image du visage en couleur\n",
        "    roi_color, w, h = extractFacesPicture(image);\n",
        "    # Condition de détection du visage\n",
        "    if roi_color is None:\n",
        "        return None\n",
        "    # Passage en noir et blanc pour la réduction d'information et une meilleure détection\n",
        "    gray = cv2.cvtColor(roi_color, cv2.COLOR_BGR2GRAY)\n",
        "    # Détection des yeux\n",
        "    eyes = eye_cascade.detectMultiScale(gray)\n",
        "\n",
        "    # Définition de l'image extraite\n",
        "    extracted = None\n",
        "    # Bouclage sur les yeux détectés\n",
        "    for (ex, ey, ew, eh) in eyes:\n",
        "        # Condition de détection de l'oeil supérieur droit\n",
        "        if ex < w / 2 - 50 and ey < h / 2 + 50:\n",
        "            extracted = roi_color[ey:ey + eh, ex:ex + ew]\n",
        "\n",
        "    return extracted\n",
        "\n",
        "\n",
        "# Extrait une image englobant le visage de l'utilisateur\n",
        "def extractFacesPicture(image):\n",
        "    # Méthode des ondelettes de Haar pour la détection de visage\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    # Passage en noir et blanc pour la réduction d'information et une meilleure détection\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Détection des visages\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    # Conditions de détection du visage\n",
        "    if faces is None:\n",
        "        return None, None, None\n",
        "    if len(faces) == 0:\n",
        "        return None, None, None\n",
        "    # Extraction des données sur l'image du premier visage détecté\n",
        "    (x, y, w, h) = faces[0]\n",
        "    # Extraction du 1er visage détecté sur l'image en couleur\n",
        "    extracted = image[y:y + h, x:x + w]\n",
        "    return extracted, w, h\n",
        "\n",
        "\n",
        "# Renvoie une image cv2 de la caméra\n",
        "def getCameraView(cameraSlot=0):\n",
        "    cap = cv2.VideoCapture(cameraSlot)\n",
        "    _, frame = cap.read()\n",
        "    return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kGzfdBQpcsa"
      },
      "source": [
        "# Cursor Scaling\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr5uIsdIqGVE"
      },
      "source": [
        "# Applique la pposition au curseur vis-à-vis du vecteur\r\n",
        "# déplacement de la pupille\r\n",
        "def setCursorPosition(vector):\r\n",
        "    return None\r\n",
        "\r\n",
        "\r\n",
        "# Enregistre l'approximation de déplacement du curseur\r\n",
        "# sur l'écran avec les valeurs étalons\r\n",
        "def setApproximation():\r\n",
        "    return None\r\n",
        "\r\n",
        "\r\n",
        "# Enregistre le point d'étalonnage en utilisation\r\n",
        "# la dernière position de la pupille\r\n",
        "def pointClickEvent(mouseClickEvent):\r\n",
        "    return None\r\n",
        "\r\n",
        "\r\n",
        "# Affiche les points d'étalonnage à l'écran\r\n",
        "def displayCalibratingPoints():\r\n",
        "    return None\r\n",
        "\r\n",
        "\r\n",
        "# Lance le mode étalonnage\r\n",
        "def launchCalibrating():\r\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WvdOep4phgS"
      },
      "source": [
        "# Interface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7dfXhupqR-X"
      },
      "source": [
        "# Effectue les actions liées au bouton\r\n",
        "def buttonClickEvent(mouseClickEvent):\r\n",
        "    return None\r\n",
        "\r\n",
        "\r\n",
        "# Affiche les boutons utilisateurs sur l'écran\r\n",
        "def displayButtons():\r\n",
        "    return None\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeWfBO-rpnZO"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGe06C8kqV_C"
      },
      "source": [
        "# Donne le dernier vecteur position de l'oeil calculé\r\n",
        "lastPupilPosition = [0, 0]\r\n",
        "\r\n",
        "# Donne l'approximation calculée lors de l'échellonnage\r\n",
        "approximation = 0.0\r\n",
        "\r\n",
        "# Liste des positions des points d'échelonnage sur l'écran\r\n",
        "buttonsLocations = [[0, 0], [0, 30], [0, 60]]\r\n",
        "\r\n",
        "# Liste des vecteurs déplacement de la pupille\r\n",
        "# enregistrés lors de l'échelonnage\r\n",
        "registeredApproximations = []\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}